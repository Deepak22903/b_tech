{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. import and install necessary libraries"
      ],
      "metadata": {
        "id": "Xhx59khxTMUO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5cU8NzwS94L",
        "outputId": "ca86dfe9-f0f0-4e86-bed1-9b99462b9ad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries (if not already installed)\n",
        "!pip install nltk scikit-learn\n",
        "\n",
        "# Import libraries\n",
        "import nltk\n",
        "from nltk.corpus import treebank\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import math\n",
        "from collections import defaultdict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. nltk data"
      ],
      "metadata": {
        "id": "BbxWAS_jTWQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK data\n",
        "nltk.download('treebank')\n",
        "nltk.download('universal_tagset')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgQCQeB_TRSD",
        "outputId": "452c4885-f30e-4ba0-eb34-cd38acee50e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. split of datasets, train and test"
      ],
      "metadata": {
        "id": "mA0qniFPTjWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and split the dataset\n",
        "sentences = treebank.tagged_sents(tagset='universal')\n",
        "trainData, testData = train_test_split(sentences, test_size=0.7, random_state=1)"
      ],
      "metadata": {
        "id": "oDjVOxQETa33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. extract words and tags"
      ],
      "metadata": {
        "id": "4DrHgbxfTwSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract unique words and tags from the training data\n",
        "wordSet = {word.lower() for sent in trainData for word, tag in sent}\n",
        "tagSet = {tag for sent in trainData for word, tag in sent}\n",
        "\n",
        "# Define mappings between tags/words and their indices\n",
        "tag_to_idx = {tag: idx for idx, tag in enumerate(sorted(tagSet))}\n",
        "idx_to_tag = {idx: tag for tag, idx in tag_to_idx.items()}\n",
        "word_to_idx = {word: idx for idx, word in enumerate(sorted(wordSet))}\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
        "\n",
        "# Add unknown word support\n",
        "word_to_idx['UNK'] = len(word_to_idx)\n",
        "idx_to_word[len(word_to_idx) - 1] = 'UNK'\n"
      ],
      "metadata": {
        "id": "fXeJYgxoTrmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5, special token and initialization of counts"
      ],
      "metadata": {
        "id": "RkRTZfizUPLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Special tokens for start and end\n",
        "START, END = '<s>', '</s>'\n",
        "tag_to_idx[START], tag_to_idx[END] = len(tag_to_idx), len(tag_to_idx) + 1\n",
        "idx_to_tag[tag_to_idx[START]], idx_to_tag[tag_to_idx[END]] = START, END\n",
        "\n",
        "# Initialize count dictionaries for tag transitions and emissions\n",
        "tagCounts = defaultdict(int)\n",
        "transitionCounts = defaultdict(int)\n",
        "emissionCounts = defaultdict(int)\n"
      ],
      "metadata": {
        "id": "yXP8XhgGUKIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. occurance count in training data"
      ],
      "metadata": {
        "id": "uWTg42ZuUtV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count occurrences in the training data\n",
        "for sent in trainData:\n",
        "    previous_tag = START\n",
        "    tagCounts[previous_tag] += 1\n",
        "    for word, tag in sent:\n",
        "        word = word.lower()\n",
        "        tagCounts[tag] += 1\n",
        "        transitionCounts[(previous_tag, tag)] += 1\n",
        "        emissionCounts[(tag, word)] += 1\n",
        "        previous_tag = tag\n",
        "    transitionCounts[(previous_tag, END)] += 1\n",
        "    tagCounts[END] += 1\n",
        "\n",
        "# Determine the number of unique tags and words (including 'UNK')\n",
        "N_tags = len(tagSet) + 2  # Plus START and END tags\n",
        "Vocab_size = len(wordSet) + 1  # Plus 'UNK'\n"
      ],
      "metadata": {
        "id": "9iIKeYk-Unh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. log probability calculation"
      ],
      "metadata": {
        "id": "kVBNL0NuVATa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Precompute denominators for probabilities\n",
        "transitionDeno = {prev_tag: tagCounts[prev_tag] + N_tags for prev_tag in tagSet | {START, END}}\n",
        "emissionDeno = {tag: tagCounts[tag] + Vocab_size for tag in tagSet | {START, END}}\n",
        "\n",
        "# Compute log probabilities for transitions and emissions\n",
        "log_transition_probs = {\n",
        "    prev_tag: {curr_tag: math.log((transitionCounts.get((prev_tag, curr_tag), 0) + 1) / transitionDeno[prev_tag])\n",
        "               for curr_tag in tagSet | {START, END}}\n",
        "    for prev_tag in tagSet | {START, END}\n",
        "}\n",
        "\n",
        "log_emission_probs = {\n",
        "    tag: {word: math.log((emissionCounts.get((tag, word), 0) + 1) / emissionDeno[tag])\n",
        "          for word in wordSet | {'UNK'}}\n",
        "    for tag in tagSet\n",
        "}\n"
      ],
      "metadata": {
        "id": "del2rE4IU7l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. viterbi algo"
      ],
      "metadata": {
        "id": "1E-TbyKrVXB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Viterbi algorithm\n",
        "def viterbiAlgo(sequence, tag_set, transition_probs, emission_probs, START, END):\n",
        "    V = [{}]\n",
        "    paths = {}\n",
        "\n",
        "    # Initialize probabilities for the first word in the sequence\n",
        "    for tag in tag_set - {START, END}:\n",
        "        trans_prob = transition_probs[START].get(tag, math.log(1 / transitionDeno[START]))\n",
        "        emit_prob = emission_probs[tag].get(sequence[0], emission_probs[tag]['UNK'])\n",
        "        V[0][tag] = trans_prob + emit_prob\n",
        "        paths[tag] = [tag]\n",
        "\n",
        "    # Process each word in the sequence\n",
        "    for t in range(1, len(sequence)):\n",
        "        V.append({})\n",
        "        new_paths = {}\n",
        "\n",
        "        for curr_tag in tag_set - {START, END}:\n",
        "            max_prob, best_prev_tag = max(\n",
        "                (V[t-1][prev_tag] + transition_probs[prev_tag].get(curr_tag, math.log(1 / transitionDeno[prev_tag])) +\n",
        "                 emission_probs[curr_tag].get(sequence[t], emission_probs[curr_tag]['UNK']), prev_tag)\n",
        "                for prev_tag in tag_set - {START, END}\n",
        "            )\n",
        "            V[t][curr_tag] = max_prob\n",
        "            new_paths[curr_tag] = paths[best_prev_tag] + [curr_tag]\n",
        "\n",
        "        paths = new_paths\n",
        "\n",
        "    # Calculate final transition to END\n",
        "    n = len(sequence) - 1\n",
        "    max_prob, best_tag = max(\n",
        "        (V[n][tag] + transition_probs[tag].get(END, math.log(1 / transitionDeno[tag])), tag)\n",
        "        for tag in tag_set - {START, END}\n",
        "    )\n",
        "\n",
        "    return paths[best_tag]\n",
        "\n",
        "# Tag a sequence of words using Viterbi\n",
        "def tag_sentence(sentence):\n",
        "    lower_sentence = [word.lower() for word in sentence]\n",
        "    return list(zip(lower_sentence, viterbiAlgo(lower_sentence, tagSet, log_transition_probs, log_emission_probs, START, END)))\n"
      ],
      "metadata": {
        "id": "wXPJG3mLVUlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. test data and model evaluation"
      ],
      "metadata": {
        "id": "MKHWVDEpVqsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare test data\n",
        "testSentences = [[word for word, tag in sent] for sent in testData]\n",
        "groundTruth = [[tag for word, tag in sent] for sent in testData]\n",
        "\n",
        "# Predict and evaluate tags for each test sentence\n",
        "predicted = [tag_sentence(sentence) for sentence in testSentences]\n",
        "predicted_tags = [tag for sent in predicted for word, tag in sent]\n",
        "ground_truth_tags = [tag for sent in groundTruth for tag in sent]\n",
        "\n",
        "# Evaluate the accuracy of the model\n",
        "accuracy = accuracy_score(ground_truth_tags, predicted_tags)\n",
        "print(\"Model Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPzeaRtPVmD9",
        "outputId": "72bc197d-a2df-4802-daa0-52ee7876bd99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.8608137960521628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QWHJt95GV2xz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}