{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install nltk\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import wordnet_ic\n",
        "from nltk.wsd import lesk\n",
        "\n",
        "# Download necessary resources if they are not already installed\n",
        "nltk.download('wordnet')\n",
        "nltk.download('wordnet_ic')\n",
        "nltk.download('brown')\n",
        "\n",
        "# Load the Brown information content (IC)\n",
        "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
        "\n",
        "# 1) Find the lowest common hypernym for any given pair of words as per WordNet\n",
        "def lowest_common_hypernym(word1, word2):\n",
        "    synsets1 = wn.synsets(word1)\n",
        "    synsets2 = wn.synsets(word2)\n",
        "    if synsets1 and synsets2:\n",
        "        # Get lowest common hypernym for first sense of both words\n",
        "        return synsets1[0].lowest_common_hypernyms(synsets2[0])\n",
        "    return None\n",
        "\n",
        "# 2) Find Lin similarity between any two words as per WordNet. Use Brown information content.\n",
        "def lin_similarity(word1, word2):\n",
        "    synsets1 = wn.synsets(word1)\n",
        "    synsets2 = wn.synsets(word2)\n",
        "    if synsets1 and synsets2:\n",
        "        # Calculate Lin similarity between the first senses\n",
        "        return synsets1[0].lin_similarity(synsets2[0], brown_ic)\n",
        "    return None\n",
        "\n",
        "# 3) Find Resnik similarity between any two words as per WordNet. Use Brown information content.\n",
        "def resnik_similarity(word1, word2):\n",
        "    synsets1 = wn.synsets(word1)\n",
        "    synsets2 = wn.synsets(word2)\n",
        "    if synsets1 and synsets2:\n",
        "        # Calculate Resnik similarity between the first senses\n",
        "        return synsets1[0].res_similarity(synsets2[0], brown_ic)\n",
        "    return None\n",
        "\n",
        "# 4) Find Jiang-Conrath distance between any two concepts as per WordNet.\n",
        "def jiang_conrath_distance(word1, word2):\n",
        "    synsets1 = wn.synsets(word1)\n",
        "    synsets2 = wn.synsets(word2)\n",
        "    if synsets1 and synsets2:\n",
        "        # Calculate Jiang-Conrath distance between the first senses\n",
        "        return synsets1[0].jcn_similarity(synsets2[0], brown_ic)\n",
        "    return None\n",
        "\n",
        "# 5) Find Leacock-Chodorow similarity between any two concepts as per WordNet.\n",
        "def leacock_chodorow_similarity(word1, word2):\n",
        "    synsets1 = wn.synsets(word1)\n",
        "    synsets2 = wn.synsets(word2)\n",
        "    if synsets1 and synsets2:\n",
        "        # Calculate Leacock-Chodorow similarity between the first senses\n",
        "        return synsets1[0].lch_similarity(synsets2[0])\n",
        "    return None\n",
        "\n",
        "# 6) Using senses from WordNet, find the appropriate sense for an ambiguous word in a sentence as per the Lesk algorithm.\n",
        "def disambiguate_lesk(word, sentence):\n",
        "    return lesk(sentence.split(), word)\n",
        "\n",
        "# Function to write results to a text file\n",
        "def write_results_to_file(filename, word1, word2, sentence):\n",
        "    with open(filename, 'w') as f:\n",
        "        # Calculate each similarity measure and disambiguation result\n",
        "        lowest_hypernym = lowest_common_hypernym(word1, word2)\n",
        "        lin_sim = lin_similarity(word1, word2)\n",
        "        resnik_sim = resnik_similarity(word1, word2)\n",
        "        jcn_dist = jiang_conrath_distance(word1, word2)\n",
        "        lch_sim = leacock_chodorow_similarity(word1, word2)\n",
        "        disambiguation = disambiguate_lesk(\"bank\", sentence)\n",
        "\n",
        "        # Write each result to the file\n",
        "        f.write(f\"Lowest common hypernym between '{word1}' and '{word2}': {lowest_hypernym}\\n\")\n",
        "        f.write(f\"Lin similarity between '{word1}' and '{word2}': {lin_sim}\\n\")\n",
        "        f.write(f\"Resnik similarity between '{word1}' and '{word2}': {resnik_sim}\\n\")\n",
        "        f.write(f\"Jiang-Conrath distance between '{word1}' and '{word2}': {jcn_dist}\\n\")\n",
        "        f.write(f\"Leacock-Chodorow similarity between '{word1}' and '{word2}': {lch_sim}\\n\")\n",
        "        f.write(f\"Lesk disambiguation for 'bank' in '{sentence}': {disambiguation} - {disambiguation.definition() if disambiguation else 'No sense found'}\\n\")\n",
        "\n",
        "# Define words and sentence for testing\n",
        "word1 = \"dog\"\n",
        "word2 = \"cat\"\n",
        "sentence = \"I went to the bank to deposit my money.\"\n",
        "\n",
        "# Call the function to write results to 'output.txt'\n",
        "write_results_to_file(\"output.txt\", word1, word2, sentence)\n",
        "\n",
        "print(\"Results saved to output.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tpx4PXdelmZs",
        "outputId": "e0b2aae7-a77c-497e-fd85-fd0bcbf21a82"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to output.txt\n"
          ]
        }
      ]
    }
  ]
}